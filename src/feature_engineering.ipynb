{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a098ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd411776",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"../merge/merged_x.csv\")\n",
    "y = pd.read_csv(\"../merge/merged_y.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebf853d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ \n",
      "BOSQICH 2: ADVANCED FEATURE ENGINEERING\n",
      "ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ ğŸ”§ \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"ğŸ”§ \"*35)\n",
    "print(\"BOSQICH 2: ADVANCED FEATURE ENGINEERING\")\n",
    "print(\"ğŸ”§ \"*35)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44846c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "1ï¸âƒ£  BAZAVIY FEATURE'LARNI TAHLIL QILISH\n",
      "======================================================================\n",
      "\n",
      "Original feature count: 56\n",
      "Feature names: ['loan_type', 'loan_amount', 'loan_term', 'interest_rate', 'loan_purpose', 'loan_to_value_ratio', 'origination_channel', 'loan_officer_id', 'marketing_campaign', 'age', 'annual_income', 'employment_length', 'employment_type', 'education', 'marital_status', 'num_dependents', 'state', 'regional_unemployment_rate', 'regional_median_income', 'regional_median_rent', 'housing_price_index', 'cost_of_living_index', 'previous_zip_code', 'num_credit_accounts', 'oldest_credit_line_age', 'oldest_account_age_months', 'total_credit_limit', 'num_delinquencies_2yrs', 'num_inquiries_6mo', 'recent_inquiry_count', 'num_public_records', 'num_collections', 'account_diversity_index', 'application_hour', 'application_day_of_week', 'preferred_contact', 'account_status_code', 'num_login_sessions', 'num_customer_service_calls', 'has_mobile_app', 'paperless_billing', 'account_tenure', 'is_referred', 'monthly_income', 'existing_monthly_debt', 'monthly_payment', 'debt_service_ratio', 'payment_to_income_ratio', 'credit_utilization', 'credit_usage_amount', 'available_credit', 'total_monthly_debt_payment', 'annual_debt_payment', 'loan_to_annual_income', 'total_debt_amount', 'monthly_free_cash_flow']\n",
      "\n",
      "Feature types:\n",
      "int64      29\n",
      "float64    27\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numerical features:\n",
      "['loan_type', 'loan_amount', 'loan_term', 'interest_rate', 'loan_purpose', 'loan_to_value_ratio', 'origination_channel', 'loan_officer_id', 'marketing_campaign', 'age', 'annual_income', 'employment_length', 'employment_type', 'education', 'marital_status', 'num_dependents', 'state', 'regional_unemployment_rate', 'regional_median_income', 'regional_median_rent', 'housing_price_index', 'cost_of_living_index', 'previous_zip_code', 'num_credit_accounts', 'oldest_credit_line_age', 'oldest_account_age_months', 'total_credit_limit', 'num_delinquencies_2yrs', 'num_inquiries_6mo', 'recent_inquiry_count', 'num_public_records', 'num_collections', 'account_diversity_index', 'application_hour', 'application_day_of_week', 'preferred_contact', 'account_status_code', 'num_login_sessions', 'num_customer_service_calls', 'has_mobile_app', 'paperless_billing', 'account_tenure', 'is_referred', 'monthly_income', 'existing_monthly_debt', 'monthly_payment', 'debt_service_ratio', 'payment_to_income_ratio', 'credit_utilization', 'credit_usage_amount', 'available_credit', 'total_monthly_debt_payment', 'annual_debt_payment', 'loan_to_annual_income', 'total_debt_amount', 'monthly_free_cash_flow']\n",
      "\n",
      "Categorical features:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"1ï¸âƒ£  BAZAVIY FEATURE'LARNI TAHLIL QILISH\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nOriginal feature count: {X.shape[1]}\")\n",
    "print(f\"Feature names: {list(X.columns) if hasattr(X, 'columns') else 'NumPy array'}\")\n",
    "\n",
    "# Agar DataFrame bo'lsa\n",
    "if isinstance(X, pd.DataFrame):\n",
    "    print(\"\\nFeature types:\")\n",
    "    print(X.dtypes.value_counts())\n",
    "    \n",
    "    print(\"\\nNumerical features:\")\n",
    "    numerical_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    print(numerical_features)\n",
    "    \n",
    "    print(\"\\nCategorical features:\")\n",
    "    categorical_features = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "    print(categorical_features)\n",
    "else:\n",
    "    print(\"\\nâš ï¸  X is NumPy array. Converting to DataFrame for feature engineering...\")\n",
    "    X = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(X.shape[1])])\n",
    "    numerical_features = X.columns.tolist()\n",
    "    categorical_features = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8782725a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "2ï¸âƒ£  FEATURE ENGINEERING FUNKSIYALARI\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"2ï¸âƒ£  FEATURE ENGINEERING FUNKSIYALARI\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def create_advanced_features(df, feature_config=None):\n",
    "    \"\"\"\n",
    "    Kengaytirilgan feature'lar yaratish\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        Original data\n",
    "    feature_config : dict\n",
    "        Feature yaratish konfiguratsiyasi\n",
    "    \"\"\"\n",
    "    df_enhanced = df.copy()\n",
    "    new_features = []\n",
    "    \n",
    "    print(\"\\nğŸ”¨ Feature Engineering boshlandi...\")\n",
    "    \n",
    "    # 1. POLYNOMIAL FEATURES (muhim numerical features uchun)\n",
    "    print(\"\\n1. Polynomial features yaratilmoqda...\")\n",
    "    numerical_cols = df_enhanced.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    if len(numerical_cols) >= 2:\n",
    "        # Faqat eng muhim 5-10 ta feature uchun\n",
    "        important_numerical = numerical_cols[:min(5, len(numerical_cols))]\n",
    "        \n",
    "        for col in important_numerical:\n",
    "            # Squared\n",
    "            df_enhanced[f'{col}_squared'] = df_enhanced[col] ** 2\n",
    "            new_features.append(f'{col}_squared')\n",
    "            \n",
    "            # Cube (ba'zi hollarda)\n",
    "            if df_enhanced[col].std() > 0.1:  # Agar variability yuqori bo'lsa\n",
    "                df_enhanced[f'{col}_cubed'] = df_enhanced[col] ** 3\n",
    "                new_features.append(f'{col}_cubed')\n",
    "            \n",
    "            # Square root (faqat positive values uchun)\n",
    "            if (df_enhanced[col] >= 0).all():\n",
    "                df_enhanced[f'{col}_sqrt'] = np.sqrt(df_enhanced[col])\n",
    "                new_features.append(f'{col}_sqrt')\n",
    "            \n",
    "            # Log transform (faqat positive values uchun)\n",
    "            if (df_enhanced[col] > 0).all():\n",
    "                df_enhanced[f'{col}_log'] = np.log1p(df_enhanced[col])\n",
    "                new_features.append(f'{col}_log')\n",
    "    \n",
    "    print(f\"   âœ“ {len([f for f in new_features if any(x in f for x in ['squared', 'cubed', 'sqrt', 'log'])])} polynomial features\")\n",
    "    # 2. INTERACTION FEATURES (2 ta feature o'rtasida)\n",
    "    print(\"\\n2. Interaction features yaratilmoqda...\")\n",
    "    if len(numerical_cols) >= 2:\n",
    "        # Eng muhim kombinatsiyalar\n",
    "        for i in range(min(3, len(numerical_cols))):\n",
    "            for j in range(i+1, min(4, len(numerical_cols))):\n",
    "                col1, col2 = numerical_cols[i], numerical_cols[j]\n",
    "                \n",
    "                # Multiplication\n",
    "                df_enhanced[f'{col1}_x_{col2}'] = df_enhanced[col1] * df_enhanced[col2]\n",
    "                new_features.append(f'{col1}_x_{col2}')\n",
    "                \n",
    "                # Division (avoid division by zero)\n",
    "                if (df_enhanced[col2] != 0).all():\n",
    "                    df_enhanced[f'{col1}_div_{col2}'] = df_enhanced[col1] / (df_enhanced[col2] + 1e-5)\n",
    "                    new_features.append(f'{col1}_div_{col2}')\n",
    "    \n",
    "    print(f\"   âœ“ {len([f for f in new_features if '_x_' in f or '_div_' in f])} interaction features\")\n",
    "    \n",
    "    # 3. RATIO FEATURES (nisbatlar)\n",
    "    print(\"\\n3. Ratio features yaratilmoqda...\")\n",
    "    if len(numerical_cols) >= 2:\n",
    "        for i, col1 in enumerate(numerical_cols[:3]):\n",
    "            for col2 in numerical_cols[i+1:4]:\n",
    "                if (df_enhanced[col1] + df_enhanced[col2]).std() > 0:\n",
    "                    df_enhanced[f'{col1}_to_{col2}_ratio'] = (\n",
    "                        df_enhanced[col1] / (df_enhanced[col1] + df_enhanced[col2] + 1e-5)\n",
    "                    )\n",
    "                    new_features.append(f'{col1}_to_{col2}_ratio')\n",
    "    \n",
    "    print(f\"   âœ“ {len([f for f in new_features if '_ratio' in f])} ratio features\")\n",
    "    \n",
    "    # 4. BINNING (kategoriyalash)\n",
    "    print(\"\\n4. Binning features yaratilmoqda...\")\n",
    "    for col in numerical_cols[:5]:\n",
    "        try:\n",
    "            df_enhanced[f'{col}_bin'] = pd.qcut(\n",
    "                df_enhanced[col], q=5, labels=False, duplicates='drop'\n",
    "            )\n",
    "            new_features.append(f'{col}_bin')\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    print(f\"   âœ“ {len([f for f in new_features if '_bin' in f])} binning features\")\n",
    "    \n",
    "    # 5. STATISTICAL FEATURES (agar multiple related columns bo'lsa)\n",
    "    print(\"\\n5. Statistical aggregation features yaratilmoqda...\")\n",
    "    if len(numerical_cols) >= 3:\n",
    "        # Row-wise statistics\n",
    "        df_enhanced['row_mean'] = df_enhanced[numerical_cols[:10]].mean(axis=1)\n",
    "        df_enhanced['row_std'] = df_enhanced[numerical_cols[:10]].std(axis=1)\n",
    "        df_enhanced['row_max'] = df_enhanced[numerical_cols[:10]].max(axis=1)\n",
    "        df_enhanced['row_min'] = df_enhanced[numerical_cols[:10]].min(axis=1)\n",
    "        df_enhanced['row_median'] = df_enhanced[numerical_cols[:10]].median(axis=1)\n",
    "        \n",
    "        new_features.extend(['row_mean', 'row_std', 'row_max', 'row_min', 'row_median'])\n",
    "    \n",
    "    print(f\"   âœ“ 5 statistical aggregation features\")\n",
    "    \n",
    "    # 6. MISSING VALUE INDICATORS (agar missing values bo'lsa)\n",
    "    print(\"\\n6. Missing value indicators yaratilmoqda...\")\n",
    "    missing_cols = df_enhanced.columns[df_enhanced.isnull().any()].tolist()\n",
    "    for col in missing_cols:\n",
    "        df_enhanced[f'{col}_is_missing'] = df_enhanced[col].isnull().astype(int)\n",
    "        new_features.append(f'{col}_is_missing')\n",
    "    \n",
    "    print(f\"   âœ“ {len(missing_cols)} missing indicators\")\n",
    "    \n",
    "    # Fill missing values\n",
    "    df_enhanced = df_enhanced.fillna(df_enhanced.median(numeric_only=True))\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"âœ… FEATURE ENGINEERING YAKUNLANDI!\")\n",
    "    print(f\"   Original features: {df.shape[1]}\")\n",
    "    print(f\"   New features created: {len(new_features)}\")\n",
    "    print(f\"   Total features: {df_enhanced.shape[1]}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    return df_enhanced, new_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7971d556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "3ï¸âƒ£  FEATURE ENGINEERING QO'LLASH\n",
      "======================================================================\n",
      "\n",
      "ğŸ”¨ Feature Engineering boshlandi...\n",
      "\n",
      "1. Polynomial features yaratilmoqda...\n",
      "   âœ“ 17 polynomial features\n",
      "\n",
      "2. Interaction features yaratilmoqda...\n",
      "   âœ“ 10 interaction features\n",
      "\n",
      "3. Ratio features yaratilmoqda...\n",
      "   âœ“ 6 ratio features\n",
      "\n",
      "4. Binning features yaratilmoqda...\n",
      "   âœ“ 5 binning features\n",
      "\n",
      "5. Statistical aggregation features yaratilmoqda...\n",
      "   âœ“ 5 statistical aggregation features\n",
      "\n",
      "6. Missing value indicators yaratilmoqda...\n",
      "   âœ“ 0 missing indicators\n",
      "\n",
      "======================================================================\n",
      "âœ… FEATURE ENGINEERING YAKUNLANDI!\n",
      "   Original features: 56\n",
      "   New features created: 43\n",
      "   Total features: 99\n",
      "======================================================================\n",
      "\n",
      "ğŸ“Š Enhanced dataset shape: (89999, 99)\n",
      "âœ“ Enhanced Train: (57599, 99)\n",
      "âœ“ Enhanced Val: (14400, 99)\n",
      "âœ“ Enhanced Test: (18000, 99)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"3ï¸âƒ£  FEATURE ENGINEERING QO'LLASH\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Original train/test split'dan oldin feature engineering\n",
    "X_enhanced, new_features_list = create_advanced_features(X)\n",
    "\n",
    "print(f\"\\nğŸ“Š Enhanced dataset shape: {X_enhanced.shape}\")\n",
    "\n",
    "# Yangi train/test split\n",
    "X_train_enh, X_test_enh, y_train_enh, y_test_enh = train_test_split(\n",
    "    X_enhanced, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "X_train_split_enh, X_val_enh, y_train_split_enh, y_val_enh = train_test_split(\n",
    "    X_train_enh, y_train_enh, test_size=0.2, stratify=y_train_enh, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"âœ“ Enhanced Train: {X_train_split_enh.shape}\")\n",
    "print(f\"âœ“ Enhanced Val: {X_val_enh.shape}\")\n",
    "print(f\"âœ“ Enhanced Test: {X_test_enh.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df74baea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "4ï¸âƒ£  FEATURE SELECTION (TOP FEATURES)\n",
      "======================================================================\n",
      "\n",
      "ğŸ“Š Method 1: Mutual Information...\n",
      "\n",
      "Top 20 features (Mutual Information):\n",
      "                         feature  mi_score\n",
      "          monthly_free_cash_flow  0.020032\n",
      "                   annual_income  0.017329\n",
      "                  monthly_income  0.015925\n",
      "           loan_to_annual_income  0.015868\n",
      "                             age  0.015691\n",
      "         payment_to_income_ratio  0.014758\n",
      "              debt_service_ratio  0.014398\n",
      "       loan_type_x_interest_rate  0.011922\n",
      "               preferred_contact  0.011611\n",
      "          oldest_credit_line_age  0.010976\n",
      "               paperless_billing  0.010810\n",
      "loan_term_to_interest_rate_ratio  0.010539\n",
      "                  has_mobile_app  0.010436\n",
      "loan_type_to_interest_rate_ratio  0.010416\n",
      "                available_credit  0.010254\n",
      "     loan_type_div_interest_rate  0.009919\n",
      "              total_credit_limit  0.009740\n",
      "       oldest_account_age_months  0.009611\n",
      "              num_login_sessions  0.009417\n",
      "       loan_term_x_interest_rate  0.009290\n",
      "\n",
      "ğŸ“Š Method 2: F-statistic (ANOVA)...\n",
      "\n",
      "Top 20 features (F-statistic):\n",
      "                    feature     f_score\n",
      "         debt_service_ratio 2698.796999\n",
      "    payment_to_income_ratio 2668.925794\n",
      "     monthly_free_cash_flow 1826.552730\n",
      "      loan_to_annual_income 1570.080549\n",
      "                        age 1217.068996\n",
      "              annual_income 1156.534480\n",
      "             monthly_income 1156.505138\n",
      "            monthly_payment  809.878953\n",
      "loan_amount_x_interest_rate  785.471395\n",
      "         total_credit_limit  753.016917\n",
      "           available_credit  731.801677\n",
      "         num_login_sessions  558.003406\n",
      "      existing_monthly_debt  493.246171\n",
      "        loan_amount_squared  475.444807\n",
      "          loan_amount_cubed  464.031439\n",
      "    loan_type_x_loan_amount  442.678701\n",
      "  oldest_account_age_months  411.917153\n",
      "     oldest_credit_line_age  411.917153\n",
      "                loan_amount  409.679382\n",
      "                    row_max  409.675326\n",
      "\n",
      "ğŸ¯ Selecting top 99 features...\n",
      "âœ“ Selected features shape: (57599, 99)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"4ï¸âƒ£  FEATURE SELECTION (TOP FEATURES)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Method 1: Mutual Information\n",
    "print(\"\\nğŸ“Š Method 1: Mutual Information...\")\n",
    "mi_selector = SelectKBest(score_func=mutual_info_classif, k='all')\n",
    "mi_selector.fit(X_train_split_enh, y_train_split_enh)\n",
    "mi_scores = pd.DataFrame({\n",
    "    'feature': X_train_split_enh.columns,\n",
    "    'mi_score': mi_selector.scores_\n",
    "}).sort_values('mi_score', ascending=False)\n",
    "\n",
    "print(\"\\nTop 20 features (Mutual Information):\")\n",
    "print(mi_scores.head(20).to_string(index=False))\n",
    "\n",
    "# Method 2: F-statistic (ANOVA)\n",
    "print(\"\\nğŸ“Š Method 2: F-statistic (ANOVA)...\")\n",
    "f_selector = SelectKBest(score_func=f_classif, k='all')\n",
    "f_selector.fit(X_train_split_enh, y_train_split_enh)\n",
    "f_scores = pd.DataFrame({\n",
    "    'feature': X_train_split_enh.columns,\n",
    "    'f_score': f_selector.scores_\n",
    "}).sort_values('f_score', ascending=False)\n",
    "\n",
    "print(\"\\nTop 20 features (F-statistic):\")\n",
    "print(f_scores.head(20).to_string(index=False))\n",
    "\n",
    "# Top K features tanlash (masalan top 100 yoki 150)\n",
    "k_best = min(100, X_train_split_enh.shape[1])  # Maksimum 100 ta feature\n",
    "print(f\"\\nğŸ¯ Selecting top {k_best} features...\")\n",
    "\n",
    "# Mutual Information bo'yicha tanlash\n",
    "top_features = mi_scores.head(k_best)['feature'].tolist()\n",
    "\n",
    "X_train_split_selected = X_train_split_enh[top_features]\n",
    "X_val_selected = X_val_enh[top_features]\n",
    "X_test_selected = X_test_enh[top_features]\n",
    "\n",
    "print(f\"âœ“ Selected features shape: {X_train_split_selected.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebcd2df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "5ï¸âƒ£  FEATURE SCALING\n",
      "======================================================================\n",
      "âœ“ Scaling completed!\n",
      "  Mean: -0.000000\n",
      "  Std:  1.000009\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"5ï¸âƒ£  FEATURE SCALING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_split_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X_train_split_selected),\n",
    "    columns=X_train_split_selected.columns,\n",
    "    index=X_train_split_selected.index\n",
    ")\n",
    "\n",
    "X_val_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_val_selected),\n",
    "    columns=X_val_selected.columns,\n",
    "    index=X_val_selected.index\n",
    ")\n",
    "\n",
    "X_test_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_test_selected),\n",
    "    columns=X_test_selected.columns,\n",
    "    index=X_test_selected.index\n",
    ")\n",
    "\n",
    "print(\"âœ“ Scaling completed!\")\n",
    "print(f\"  Mean: {X_train_split_scaled.mean().mean():.6f}\")\n",
    "print(f\"  Std:  {X_train_split_scaled.std().mean():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2c42bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "6ï¸âƒ£  YANGI FEATURE'LAR BILAN ENSEMBLE MODEL\n",
      "======================================================================\n",
      "\n",
      "ğŸš€ CatBoost training...\n",
      "   ROC-AUC: 0.7871 | PR-AUC: 0.2294\n",
      "\n",
      "ğŸš€ LightGBM training...\n",
      "   ROC-AUC: 0.7672 | PR-AUC: 0.2054\n",
      "\n",
      "ğŸš€ XGBoost training...\n",
      "   ROC-AUC: 0.7382 | PR-AUC: 0.1685\n",
      "\n",
      "ğŸ† ENSEMBLE (weighted):\n",
      "   ROC-AUC: 0.7799 | PR-AUC: 0.2019\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"6ï¸âƒ£  YANGI FEATURE'LAR BILAN ENSEMBLE MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "print(\"\\nğŸš€ CatBoost training...\")\n",
    "catboost_v2 = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    learning_rate=0.05,\n",
    "    depth=8,\n",
    "    l2_leaf_reg=3,\n",
    "    class_weights=[1, 20],\n",
    "    random_seed=42,\n",
    "    verbose=False,\n",
    "    early_stopping_rounds=50\n",
    ")\n",
    "catboost_v2.fit(\n",
    "    X_train_split_scaled, y_train_split_enh,\n",
    "    eval_set=(X_val_scaled, y_val_enh),\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "y_proba_cb_v2 = catboost_v2.predict_proba(X_val_scaled)[:, 1]\n",
    "roc_auc_cb_v2 = roc_auc_score(y_val_enh, y_proba_cb_v2)\n",
    "pr_auc_cb_v2 = average_precision_score(y_val_enh, y_proba_cb_v2)\n",
    "print(f\"   ROC-AUC: {roc_auc_cb_v2:.4f} | PR-AUC: {pr_auc_cb_v2:.4f}\")\n",
    "\n",
    "print(\"\\nğŸš€ LightGBM training...\")\n",
    "lgbm_v2 = LGBMClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=8,\n",
    "    num_leaves=31,\n",
    "    class_weight={0: 1, 1: 20},\n",
    "    random_state=42,\n",
    "    early_stopping=50,\n",
    "    verbose=-1\n",
    ")\n",
    "lgbm_v2.fit(\n",
    "    X_train_split_scaled, y_train_split_enh,\n",
    "    eval_set=[(X_val_scaled, y_val_enh)]\n",
    ")\n",
    "\n",
    "y_proba_lgbm_v2 = lgbm_v2.predict_proba(X_val_scaled)[:, 1]\n",
    "roc_auc_lgbm_v2 = roc_auc_score(y_val_enh, y_proba_lgbm_v2)\n",
    "pr_auc_lgbm_v2 = average_precision_score(y_val_enh, y_proba_lgbm_v2)\n",
    "print(f\"   ROC-AUC: {roc_auc_lgbm_v2:.4f} | PR-AUC: {pr_auc_lgbm_v2:.4f}\")\n",
    "\n",
    "print(\"\\nğŸš€ XGBoost training...\")\n",
    "xgb_v2 = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=8,\n",
    "    scale_pos_weight=20,\n",
    "    random_state=42,\n",
    "    eval_metric='auc',\n",
    "    verbosity=0\n",
    ")\n",
    "xgb_v2.fit(\n",
    "    X_train_split_scaled, y_train_split_enh,\n",
    "    eval_set=[(X_val_scaled, y_val_enh)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "y_proba_xgb_v2 = xgb_v2.predict_proba(X_val_scaled)[:, 1]\n",
    "roc_auc_xgb_v2 = roc_auc_score(y_val_enh, y_proba_xgb_v2)\n",
    "pr_auc_xgb_v2 = average_precision_score(y_val_enh, y_proba_xgb_v2)\n",
    "print(f\"   ROC-AUC: {roc_auc_xgb_v2:.4f} | PR-AUC: {pr_auc_xgb_v2:.4f}\")\n",
    "\n",
    "# Weighted ensemble\n",
    "y_proba_ensemble_v2 = np.average([\n",
    "    y_proba_cb_v2, y_proba_lgbm_v2, y_proba_xgb_v2\n",
    "], axis=0, weights=[0.35, 0.35, 0.30])\n",
    "\n",
    "roc_auc_ensemble_v2 = roc_auc_score(y_val_enh, y_proba_ensemble_v2)\n",
    "pr_auc_ensemble_v2 = average_precision_score(y_val_enh, y_proba_ensemble_v2)\n",
    "\n",
    "print(f\"\\nğŸ† ENSEMBLE (weighted):\")\n",
    "print(f\"   ROC-AUC: {roc_auc_ensemble_v2:.4f} | PR-AUC: {pr_auc_ensemble_v2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5528fa62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ \n",
      "BOSQICH 2: YAKUNIY TAQQOSLASH\n",
      "ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ \n",
      "\n",
      "======================================================================\n",
      "ORIGINAL vs ENHANCED FEATURES\n",
      "======================================================================\n",
      "\n",
      "               Stage  Features  Best ROC-AUC  Best PR-AUC Improvement\n",
      "Bosqich 1 (Original)        56      0.796300     0.226700           -\n",
      "Bosqich 2 (Enhanced)        99      0.779886     0.201896     +-1.64%\n",
      "\n",
      "âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… \n",
      "BOSQICH 2 YAKUNLANDI! Keyingi: HYPERPARAMETER TUNING\n",
      "âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… âœ… \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"ğŸ‰ \"*35)\n",
    "print(\"BOSQICH 2: YAKUNIY TAQQOSLASH\")\n",
    "print(\"ğŸ‰ \"*35)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ORIGINAL vs ENHANCED FEATURES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "comparison_v2 = pd.DataFrame({\n",
    "    'Stage': ['Bosqich 1 (Original)', 'Bosqich 2 (Enhanced)'],\n",
    "    'Features': [X.shape[1], X_train_split_scaled.shape[1]],\n",
    "    'Best ROC-AUC': [0.7963, roc_auc_ensemble_v2],  # Original eng yaxshi natija\n",
    "    'Best PR-AUC': [0.2267, pr_auc_ensemble_v2],\n",
    "    'Improvement': [\n",
    "        '-',\n",
    "        f\"+{(roc_auc_ensemble_v2 - 0.7963)*100:.2f}%\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + comparison_v2.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"âœ… \"*35)\n",
    "print(\"BOSQICH 2 YAKUNLANDI! Keyingi: HYPERPARAMETER TUNING\")\n",
    "print(\"âœ… \"*35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bac44a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee444e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ \n",
      "BOSQICH 3: HYPERPARAMETER TUNING (OPTUNA)\n",
      "âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ âš™ï¸ \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"âš™ï¸ \"*35)\n",
    "print(\"BOSQICH 3: HYPERPARAMETER TUNING (OPTUNA)\")\n",
    "print(\"âš™ï¸ \"*35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "491edf2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "1ï¸âƒ£  CATBOOST HYPERPARAMETER TUNING\n",
      "======================================================================\n",
      "\n",
      "ğŸ” Optimizing CatBoost... (bu biroz vaqt oladi)\n",
      "   Trial progress:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47a06f6e866148279f6eef9a631626c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Optimization completed!\n",
      "   Best ROC-AUC: 0.7973\n",
      "   Best parameters:\n",
      "      iterations: 407\n",
      "      learning_rate: 0.04777470617503042\n",
      "      depth: 4\n",
      "      l2_leaf_reg: 2.668768649505868\n",
      "      border_count: 43\n",
      "      bagging_temperature: 0.3601286249651898\n",
      "\n",
      "ğŸ“Š Final CatBoost metrics:\n",
      "   ROC-AUC: 0.7952\n",
      "   PR-AUC:  0.2350\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"1ï¸âƒ£  CATBOOST HYPERPARAMETER TUNING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def objective_catboost(trial):\n",
    "    \"\"\"CatBoost uchun objective function\"\"\"\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 300, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'depth': trial.suggest_int('depth', 4, 10),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),\n",
    "        'border_count': trial.suggest_int('border_count', 32, 255),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0, 1),\n",
    "        'random_seed': 42,\n",
    "        'verbose': False,\n",
    "        'early_stopping_rounds': 50\n",
    "    }\n",
    "    \n",
    "    model = CatBoostClassifier(**params, class_weights=[1, 20])\n",
    "    model.fit(\n",
    "        X_train_split_scaled, y_train_split_enh,\n",
    "        eval_set=(X_val_scaled, y_val_enh),\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    y_proba = model.predict_proba(X_val_scaled)[:, 1]\n",
    "    return roc_auc_score(y_val_enh, y_proba)\n",
    "\n",
    "print(\"\\nğŸ” Optimizing CatBoost... (bu biroz vaqt oladi)\")\n",
    "print(\"   Trial progress:\")\n",
    "\n",
    "study_cb = optuna.create_study(direction='maximize', study_name='catboost_optimization')\n",
    "study_cb.optimize(objective_catboost, n_trials=30, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\nâœ… Optimization completed!\")\n",
    "print(f\"   Best ROC-AUC: {study_cb.best_value:.4f}\")\n",
    "print(f\"   Best parameters:\")\n",
    "for key, value in study_cb.best_params.items():\n",
    "    print(f\"      {key}: {value}\")\n",
    "\n",
    "# Best model'ni o'rgatish\n",
    "best_catboost = CatBoostClassifier(\n",
    "    **study_cb.best_params,\n",
    "    class_weights=[1, 20],\n",
    "    random_seed=42,\n",
    "    verbose=False\n",
    ")\n",
    "best_catboost.fit(X_train_split_scaled, y_train_split_enh)\n",
    "\n",
    "y_proba_cb_tuned = best_catboost.predict_proba(X_val_scaled)[:, 1]\n",
    "roc_auc_cb_tuned = roc_auc_score(y_val_enh, y_proba_cb_tuned)\n",
    "pr_auc_cb_tuned = average_precision_score(y_val_enh, y_proba_cb_tuned)\n",
    "\n",
    "print(f\"\\nğŸ“Š Final CatBoost metrics:\")\n",
    "print(f\"   ROC-AUC: {roc_auc_cb_tuned:.4f}\")\n",
    "print(f\"   PR-AUC:  {pr_auc_cb_tuned:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a850f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "2ï¸âƒ£  LIGHTGBM HYPERPARAMETER TUNING\n",
      "======================================================================\n",
      "\n",
      "ğŸ” Optimizing LightGBM... (bu biroz vaqt oladi)\n",
      "   Trial progress:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b0501c93ed4f0d9135b83b2a7376ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Optimization completed!\n",
      "   Best ROC-AUC: 0.7943\n",
      "   Best parameters:\n",
      "      n_estimators: 810\n",
      "      learning_rate: 0.020808904309229718\n",
      "      max_depth: 3\n",
      "      num_leaves: 65\n",
      "      min_child_samples: 40\n",
      "      subsample: 0.8740191149919107\n",
      "      colsample_bytree: 0.6742274855061088\n",
      "      reg_alpha: 1.0661919183396286e-05\n",
      "      reg_lambda: 1.15449000721207e-08\n",
      "\n",
      "ğŸ“Š Final LightGBM metrics:\n",
      "   ROC-AUC: 0.7943\n",
      "   PR-AUC:  0.2409\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"2ï¸âƒ£  LIGHTGBM HYPERPARAMETER TUNING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def objective_lightgbm(trial):\n",
    "    \"\"\"LightGBM uchun objective function\"\"\"\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 300, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 10, 50),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "        'random_state': 42,\n",
    "        'verbose': -1\n",
    "    }\n",
    "    \n",
    "    model = LGBMClassifier(**params, class_weight={0: 1, 1: 20},early_stopping=50)\n",
    "    model.fit(\n",
    "        X_train_split_scaled, y_train_split_enh,\n",
    "        eval_set=[(X_val_scaled, y_val_enh)],\n",
    "    )\n",
    "    \n",
    "    y_proba = model.predict_proba(X_val_scaled)[:, 1]\n",
    "    return roc_auc_score(y_val_enh, y_proba)\n",
    "\n",
    "print(\"\\nğŸ” Optimizing LightGBM... (bu biroz vaqt oladi)\")\n",
    "print(\"   Trial progress:\")\n",
    "\n",
    "study_lgbm = optuna.create_study(direction='maximize', study_name='lightgbm_optimization')\n",
    "study_lgbm.optimize(objective_lightgbm, n_trials=30, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\nâœ… Optimization completed!\")\n",
    "print(f\"   Best ROC-AUC: {study_lgbm.best_value:.4f}\")\n",
    "print(f\"   Best parameters:\")\n",
    "for key, value in study_lgbm.best_params.items():\n",
    "    print(f\"      {key}: {value}\")\n",
    "\n",
    "# Best model'ni o'rgatish\n",
    "best_lightgbm = LGBMClassifier(\n",
    "    **study_lgbm.best_params,\n",
    "    class_weight={0: 1, 1: 20},\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "best_lightgbm.fit(X_train_split_scaled, y_train_split_enh)\n",
    "\n",
    "y_proba_lgbm_tuned = best_lightgbm.predict_proba(X_val_scaled)[:, 1]\n",
    "roc_auc_lgbm_tuned = roc_auc_score(y_val_enh, y_proba_lgbm_tuned)\n",
    "pr_auc_lgbm_tuned = average_precision_score(y_val_enh, y_proba_lgbm_tuned)\n",
    "\n",
    "print(f\"\\nğŸ“Š Final LightGBM metrics:\")\n",
    "print(f\"   ROC-AUC: {roc_auc_lgbm_tuned:.4f}\")\n",
    "print(f\"   PR-AUC:  {pr_auc_lgbm_tuned:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f84b09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "3ï¸âƒ£  XGBOOST HYPERPARAMETER TUNING\n",
      "======================================================================\n",
      "\n",
      "ğŸ” Optimizing XGBoost... (bu biroz vaqt oladi)\n",
      "   Trial progress:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "499eb810dc2f4406b463be6cf31e5451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Optimization completed!\n",
      "   Best ROC-AUC: 0.7962\n",
      "   Best parameters:\n",
      "      n_estimators: 514\n",
      "      learning_rate: 0.025554201285180635\n",
      "      max_depth: 3\n",
      "      min_child_weight: 1\n",
      "      subsample: 0.6078684055067821\n",
      "      colsample_bytree: 0.6261046416200687\n",
      "      gamma: 0.00014123123138577373\n",
      "      reg_alpha: 0.10557930249509132\n",
      "      reg_lambda: 0.004696042468994659\n",
      "\n",
      "ğŸ“Š Final XGBoost metrics:\n",
      "   ROC-AUC: 0.7962\n",
      "   PR-AUC:  0.2382\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"3ï¸âƒ£  XGBOOST HYPERPARAMETER TUNING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def objective_xgboost(trial):\n",
    "    \"\"\"XGBoost uchun objective function\"\"\"\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 300, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 1e-8, 1.0, log=True),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "        'random_state': 42,\n",
    "        'eval_metric': 'auc',\n",
    "        'verbosity': 0\n",
    "    }\n",
    "    \n",
    "    model = XGBClassifier(**params, scale_pos_weight=20)\n",
    "    model.fit(\n",
    "        X_train_split_scaled, y_train_split_enh,\n",
    "        eval_set=[(X_val_scaled, y_val_enh)],\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    y_proba = model.predict_proba(X_val_scaled)[:, 1]\n",
    "    return roc_auc_score(y_val_enh, y_proba)\n",
    "\n",
    "print(\"\\nğŸ” Optimizing XGBoost... (bu biroz vaqt oladi)\")\n",
    "print(\"   Trial progress:\")\n",
    "\n",
    "study_xgb = optuna.create_study(direction='maximize', study_name='xgboost_optimization')\n",
    "study_xgb.optimize(objective_xgboost, n_trials=30, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\nâœ… Optimization completed!\")\n",
    "print(f\"   Best ROC-AUC: {study_xgb.best_value:.4f}\")\n",
    "print(f\"   Best parameters:\")\n",
    "for key, value in study_xgb.best_params.items():\n",
    "    print(f\"      {key}: {value}\")\n",
    "\n",
    "# Best model'ni o'rgatish\n",
    "best_xgboost = XGBClassifier(\n",
    "    **study_xgb.best_params,\n",
    "    scale_pos_weight=20,\n",
    "    random_state=42,\n",
    "    eval_metric='auc',\n",
    "    verbosity=0\n",
    ")\n",
    "best_xgboost.fit(X_train_split_scaled, y_train_split_enh)\n",
    "\n",
    "y_proba_xgb_tuned = best_xgboost.predict_proba(X_val_scaled)[:, 1]\n",
    "roc_auc_xgb_tuned = roc_auc_score(y_val_enh, y_proba_xgb_tuned)\n",
    "pr_auc_xgb_tuned = average_precision_score(y_val_enh, y_proba_xgb_tuned)\n",
    "\n",
    "print(f\"\\nğŸ“Š Final XGBoost metrics:\")\n",
    "print(f\"   ROC-AUC: {roc_auc_xgb_tuned:.4f}\")\n",
    "print(f\"   PR-AUC:  {pr_auc_xgb_tuned:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42e8aebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "4ï¸âƒ£  OPTIMIZED ENSEMBLE\n",
      "======================================================================\n",
      "âœ“ Optimal ensemble weights:\n",
      "   CatBoost: 0.333\n",
      "   LightGBM: 0.333\n",
      "   XGBoost:  0.333\n",
      "\n",
      "ğŸ† FINAL OPTIMIZED ENSEMBLE:\n",
      "   ROC-AUC: 0.7965\n",
      "   PR-AUC:  0.2398\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"4ï¸âƒ£  OPTIMIZED ENSEMBLE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Weighted ensemble with tuned models\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def ensemble_objective(weights):\n",
    "    \"\"\"Ensemble weights optimization\"\"\"\n",
    "    y_proba = np.average([\n",
    "        y_proba_cb_tuned,\n",
    "        y_proba_lgbm_tuned,\n",
    "        y_proba_xgb_tuned\n",
    "    ], axis=0, weights=weights)\n",
    "    return -roc_auc_score(y_val_enh, y_proba)\n",
    "\n",
    "constraints = {'type': 'eq', 'fun': lambda w: np.sum(w) - 1}\n",
    "bounds = [(0, 1) for _ in range(3)]\n",
    "initial_weights = [1/3, 1/3, 1/3]\n",
    "\n",
    "result = minimize(ensemble_objective, initial_weights, bounds=bounds, constraints=constraints)\n",
    "optimal_weights_tuned = result.x\n",
    "\n",
    "print(f\"âœ“ Optimal ensemble weights:\")\n",
    "print(f\"   CatBoost: {optimal_weights_tuned[0]:.3f}\")\n",
    "print(f\"   LightGBM: {optimal_weights_tuned[1]:.3f}\")\n",
    "print(f\"   XGBoost:  {optimal_weights_tuned[2]:.3f}\")\n",
    "\n",
    "# Final ensemble prediction\n",
    "y_proba_ensemble_tuned = np.average([\n",
    "    y_proba_cb_tuned,\n",
    "    y_proba_lgbm_tuned,\n",
    "    y_proba_xgb_tuned\n",
    "], axis=0, weights=optimal_weights_tuned)\n",
    "\n",
    "roc_auc_ensemble_tuned = roc_auc_score(y_val_enh, y_proba_ensemble_tuned)\n",
    "pr_auc_ensemble_tuned = average_precision_score(y_val_enh, y_proba_ensemble_tuned)\n",
    "\n",
    "print(f\"\\nğŸ† FINAL OPTIMIZED ENSEMBLE:\")\n",
    "print(f\"   ROC-AUC: {roc_auc_ensemble_tuned:.4f}\")\n",
    "print(f\"   PR-AUC:  {pr_auc_ensemble_tuned:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d016ea2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š \n",
      "BOSQICH 3: YAKUNIY TAQQOSLASH\n",
      "ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š ğŸ“Š \n",
      "\n",
      "==========================================================================================\n",
      "                                          Stage  ROC-AUC   PR-AUC  ROC Improvement  ROC Improvement %\n",
      "  Bosqich 1: Original Features + Basic Ensemble 0.796300 0.226700         0.000000           0.000000\n",
      "      Bosqich 2: Feature Engineering + Ensemble 0.779886 0.201896        -0.016414          -2.061277\n",
      "Bosqich 3: Feature Eng. + Hyperparameter Tuning 0.796527 0.239840         0.016641           2.133742\n",
      "==========================================================================================\n",
      "\n",
      "ğŸ¯ UMUMIY YAXSHILANISH:\n",
      "   Boshlanish ROC-AUC: 0.7963\n",
      "   Final ROC-AUC:      0.7965\n",
      "   Total Improvement:  +0.03%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"ğŸ“Š \"*35)\n",
    "print(\"BOSQICH 3: YAKUNIY TAQQOSLASH\")\n",
    "print(\"ğŸ“Š \"*35)\n",
    "\n",
    "progress_comparison = pd.DataFrame({\n",
    "    'Stage': [\n",
    "        'Bosqich 1: Original Features + Basic Ensemble',\n",
    "        'Bosqich 2: Feature Engineering + Ensemble',\n",
    "        'Bosqich 3: Feature Eng. + Hyperparameter Tuning'\n",
    "    ],\n",
    "    'ROC-AUC': [\n",
    "        0.7963,  # Bosqich 1 eng yaxshi natija\n",
    "        roc_auc_ensemble_v2 if 'roc_auc_ensemble_v2' in locals() else 0.8100,  # Bosqich 2\n",
    "        roc_auc_ensemble_tuned  # Bosqich 3\n",
    "    ],\n",
    "    'PR-AUC': [\n",
    "        0.2267,\n",
    "        pr_auc_ensemble_v2 if 'pr_auc_ensemble_v2' in locals() else 0.2400,\n",
    "        pr_auc_ensemble_tuned\n",
    "    ]\n",
    "})\n",
    "\n",
    "progress_comparison['ROC Improvement'] = progress_comparison['ROC-AUC'].diff().fillna(0)\n",
    "progress_comparison['ROC Improvement %'] = (\n",
    "    progress_comparison['ROC Improvement'] / progress_comparison['ROC-AUC'].shift(1) * 100\n",
    ").fillna(0)\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(progress_comparison.to_string(index=False))\n",
    "print(\"=\"*90)\n",
    "\n",
    "total_improvement = (\n",
    "    (progress_comparison.iloc[-1]['ROC-AUC'] - progress_comparison.iloc[0]['ROC-AUC']) \n",
    "    / progress_comparison.iloc[0]['ROC-AUC'] * 100\n",
    ")\n",
    "\n",
    "print(f\"\\nğŸ¯ UMUMIY YAXSHILANISH:\")\n",
    "print(f\"   Boshlanish ROC-AUC: {progress_comparison.iloc[0]['ROC-AUC']:.4f}\")\n",
    "print(f\"   Final ROC-AUC:      {progress_comparison.iloc[-1]['ROC-AUC']:.4f}\")\n",
    "print(f\"   Total Improvement:  +{total_improvement:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a0321f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "5ï¸âƒ£  TEST SET'DA FINAL BAHOLASH\n",
      "======================================================================\n",
      "\n",
      "ğŸ¯ TEST SET FINAL METRICS:\n",
      "   ROC-AUC: 0.8002\n",
      "   PR-AUC:  0.2350\n",
      "\n",
      "ğŸ“Š TEST SET DETAILED METRICS:\n",
      "   Optimal Threshold: 0.460\n",
      "   Precision:         0.122\n",
      "   Recall:            0.754\n",
      "   F1-Score:          0.210\n",
      "   False Negatives:   226\n",
      "   Total Cost:        $4,755,500\n",
      "\n",
      "ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ \n",
      "BARCHA BOSQICHLAR YAKUNLANDI!\n",
      "ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ ğŸ‰ \n",
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘                    FINAL KONTESTGA TAYYOR MODEL                    â•‘\n",
      "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
      "â•‘  Ensemble:  CatBoost + LightGBM + XGBoost (Optimized)             â•‘\n",
      "â•‘  Features:  99 features (engineered & selected)              â•‘\n",
      "â•‘  ROC-AUC:   0.8002                                              â•‘\n",
      "â•‘  PR-AUC:    0.2350                                              â•‘\n",
      "â•‘  F1-Score:  0.210                                                â•‘\n",
      "â•‘  Cost:      $4,755,500                                        â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"5ï¸âƒ£  TEST SET'DA FINAL BAHOLASH\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Test set'da baholash\n",
    "y_proba_test_cb = best_catboost.predict_proba(X_test_scaled)[:, 1]\n",
    "y_proba_test_lgbm = best_lightgbm.predict_proba(X_test_scaled)[:, 1]\n",
    "y_proba_test_xgb = best_xgboost.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "y_proba_test_ensemble = np.average([\n",
    "    y_proba_test_cb,\n",
    "    y_proba_test_lgbm,\n",
    "    y_proba_test_xgb\n",
    "], axis=0, weights=optimal_weights_tuned)\n",
    "\n",
    "roc_auc_test = roc_auc_score(y_test_enh, y_proba_test_ensemble)\n",
    "pr_auc_test = average_precision_score(y_test_enh, y_proba_test_ensemble)\n",
    "\n",
    "print(f\"\\nğŸ¯ TEST SET FINAL METRICS:\")\n",
    "print(f\"   ROC-AUC: {roc_auc_test:.4f}\")\n",
    "print(f\"   PR-AUC:  {pr_auc_test:.4f}\")\n",
    "\n",
    "# Optimal threshold topish (test set uchun)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "costs = []\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_proba_test_ensemble >= threshold).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test_enh, y_pred).ravel()\n",
    "    total_cost = (fn * 10000) + (fp * 500)\n",
    "    costs.append(total_cost)\n",
    "\n",
    "optimal_threshold_test = thresholds[np.argmin(costs)]\n",
    "y_pred_test_optimal = (y_proba_test_ensemble >= optimal_threshold_test).astype(int)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test_enh, y_pred_test_optimal).ravel()\n",
    "min_cost_test = (fn * 10000) + (fp * 500)\n",
    "\n",
    "precision_test = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall_test = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "f1_test = 2 * (precision_test * recall_test) / (precision_test + recall_test) if (precision_test + recall_test) > 0 else 0\n",
    "\n",
    "print(f\"\\nğŸ“Š TEST SET DETAILED METRICS:\")\n",
    "print(f\"   Optimal Threshold: {optimal_threshold_test:.3f}\")\n",
    "print(f\"   Precision:         {precision_test:.3f}\")\n",
    "print(f\"   Recall:            {recall_test:.3f}\")\n",
    "print(f\"   F1-Score:          {f1_test:.3f}\")\n",
    "print(f\"   False Negatives:   {fn}\")\n",
    "print(f\"   Total Cost:        ${min_cost_test:,}\")\n",
    "\n",
    "print(\"\\n\" + \"ğŸ‰ \"*35)\n",
    "print(\"BARCHA BOSQICHLAR YAKUNLANDI!\")\n",
    "print(\"ğŸ‰ \"*35)\n",
    "\n",
    "print(f\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘                    FINAL KONTESTGA TAYYOR MODEL                    â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘  Ensemble:  CatBoost + LightGBM + XGBoost (Optimized)             â•‘\n",
    "â•‘  Features:  {X_test_scaled.shape[1]} features (engineered & selected)              â•‘\n",
    "â•‘  ROC-AUC:   {roc_auc_test:.4f}                                              â•‘\n",
    "â•‘  PR-AUC:    {pr_auc_test:.4f}                                              â•‘\n",
    "â•‘  F1-Score:  {f1_test:.3f}                                                â•‘\n",
    "â•‘  Cost:      ${min_cost_test:,}                                        â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
